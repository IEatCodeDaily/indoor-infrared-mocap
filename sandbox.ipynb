{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def pose_to_matrix(pose):\n",
    "    \"\"\"Convert R, t pose to 4x4 transformation matrix\"\"\"\n",
    "    matrix = np.eye(4)\n",
    "    matrix[:3, :3] = np.array(pose['R'])\n",
    "    matrix[:3, 3] = np.array(pose['t'])\n",
    "    return matrix\n",
    "\n",
    "# Input data\n",
    "poses = [\n",
    "    {\n",
    "        \"R\": [[1,0,0],[0,1,0],[0,0,1]],\n",
    "        \"t\": [0,0,0]\n",
    "    },\n",
    "    {\n",
    "        \"R\": [[-0.0008290000610233772,-0.7947131755287576,0.6069845808584402],\n",
    "              [0.7624444396180684,0.3922492478955913,0.5146056781855716],\n",
    "              [-0.6470531579819294,0.46321862674804054,0.6055994671226776]],\n",
    "        \"t\": [-2.6049886186449047,-2.173986915510569,0.7303458563542193]\n",
    "    },\n",
    "    {\n",
    "        \"R\": [[-0.9985541623963866,-0.028079891357569067,-0.045837806036037466],\n",
    "              [-0.043210651917521686,-0.08793122558361385,0.9951888962042462],\n",
    "              [-0.03197537054848707,0.995730696156702,0.0865907408997996]],\n",
    "        \"t\": [0.8953888630067902,-3.4302652822708373,3.70967106300893]\n",
    "    },\n",
    "    {\n",
    "        \"R\": [[-0.4499864100408215,0.6855400696798954,-0.5723172578577878],\n",
    "              [-0.7145273934510732,0.10804105689305427,0.6912146801345055],\n",
    "              [0.5356891214002657,0.7199735709654319,0.4412201517663212]],\n",
    "        \"t\": [2.50141072072536,-2.313616767292231,1.8529907514099284]\n",
    "    }\n",
    "]\n",
    "\n",
    "to_world_matrix = np.array([\n",
    "    [0.9941338485260931,0.0986512964608827,-0.04433748889242502,0.9938296704767513],\n",
    "    [-0.0986512964608827,0.659022672138982,-0.7456252673517598,2.593331619023365],\n",
    "    [0.04433748889242498,-0.7456252673517594,-0.6648888236128887,2.9576262456228286],\n",
    "    [0,0,0,1]\n",
    "])\n",
    "\n",
    "# Transform each pose\n",
    "transformed_positions = []\n",
    "for pose in poses:\n",
    "    # Convert pose to matrix\n",
    "    pose_matrix = pose_to_matrix(pose)\n",
    "    \n",
    "    # Transform pose\n",
    "    transformed_matrix = to_world_matrix @ pose_matrix\n",
    "    \n",
    "    # Extract position\n",
    "    position = transformed_matrix[:3, 3]\n",
    "    transformed_positions.append(position)\n",
    "\n",
    "transformed_positions = np.array(transformed_positions)\n",
    "\n",
    "# Calculate average Z coordinate\n",
    "avg_z = np.mean(transformed_positions[:, 2])\n",
    "print(f\"Average Z coordinate: {avg_z:.4f}\")\n",
    "\n",
    "# Project all points to average Z plane\n",
    "projected_positions = transformed_positions.copy()\n",
    "projected_positions[:, 2] = avg_z\n",
    "\n",
    "# Calculate deviations from average Z plane\n",
    "deviations = np.abs(transformed_positions[:, 2] - avg_z)\n",
    "max_deviation = np.max(deviations)\n",
    "print(f\"\\nMaximum deviation from average Z plane: {max_deviation:.4f}\")\n",
    "\n",
    "print(\"\\nOriginal transformed positions:\")\n",
    "for i, pos in enumerate(transformed_positions):\n",
    "    print(f\"Camera {i}: {pos} (deviation from avg Z: {deviations[i]:.4f})\")\n",
    "\n",
    "print(\"\\nProjected positions (on average Z plane):\")\n",
    "for i, pos in enumerate(projected_positions):\n",
    "    print(f\"Camera {i}: {pos}\")\n",
    "\n",
    "# Visualize the camera positions\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot original positions\n",
    "ax.scatter(transformed_positions[:, 0], \n",
    "          transformed_positions[:, 1], \n",
    "          transformed_positions[:, 2], \n",
    "          c='blue', marker='o', label='Original')\n",
    "\n",
    "# Plot projected positions\n",
    "ax.scatter(projected_positions[:, 0], \n",
    "          projected_positions[:, 1], \n",
    "          projected_positions[:, 2], \n",
    "          c='red', marker='^', label='Projected')\n",
    "\n",
    "# Draw lines between original and projected positions\n",
    "for orig, proj in zip(transformed_positions, projected_positions):\n",
    "    ax.plot([orig[0], proj[0]], \n",
    "            [orig[1], proj[1]], \n",
    "            [orig[2], proj[2]], \n",
    "            'k--', alpha=0.3)\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.legend()\n",
    "plt.title('Camera Positions: Original vs Projected')\n",
    "plt.show()\n",
    "\n",
    "# Additional analysis: Calculate the plane normal\n",
    "def fit_plane(points):\n",
    "    \"\"\"Fit a plane to the points and return the normal vector\"\"\"\n",
    "    centroid = np.mean(points, axis=0)\n",
    "    centered_points = points - centroid\n",
    "    U, S, Vt = np.linalg.svd(centered_points)\n",
    "    normal = Vt[-1]\n",
    "    return normal / np.linalg.norm(normal)\n",
    "\n",
    "# Fit plane to original positions\n",
    "plane_normal = fit_plane(transformed_positions)\n",
    "print(\"\\nBest-fit plane normal vector:\", plane_normal)\n",
    "\n",
    "# Calculate angle between best-fit plane normal and Z-axis\n",
    "z_axis = np.array([0, 0, 1])\n",
    "angle = np.arccos(np.dot(plane_normal, z_axis))\n",
    "print(f\"Angle between best-fit plane and XY plane: {np.degrees(angle):.2f} degrees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pycolmap\n",
    "from pathlib import Path\n",
    "\n",
    "class IRMarkerDetector:\n",
    "    def __init__(self, threshold=127):\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def detect(self, frame):\n",
    "        # Basic binary threshold for IR bright spots\n",
    "        _, binary = cv2.threshold(frame, self.threshold, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Denoise if needed\n",
    "        denoised = cv2.fastNlMeansDenoising(binary)\n",
    "        \n",
    "        # Find centroids of IR LEDs\n",
    "        contours, _ = cv2.findContours(denoised, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        points = []\n",
    "        for contour in contours:\n",
    "            M = cv2.moments(contour)\n",
    "            if M[\"m00\"] != 0:\n",
    "                cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                points.append((cX, cY))\n",
    "                \n",
    "        return points, binary  # Return both points and processed image for visualization\n",
    "\n",
    "class CameraPoseEstimator:\n",
    "    def __init__(self, camera_params, marker_world_coords):\n",
    "        \"\"\"\n",
    "        camera_params: dict with camera intrinsics\n",
    "        marker_world_coords: nx3 array of real-world coordinates of IR LED markers\n",
    "        \"\"\"\n",
    "        self.camera_matrix = np.array([\n",
    "            [camera_params['fx'], 0, camera_params['cx']],\n",
    "            [0, camera_params['fy'], camera_params['cy']],\n",
    "            [0, 0, 1]\n",
    "        ])\n",
    "        self.dist_coeffs = np.array(camera_params['dist_coeffs'])\n",
    "        self.marker_world_coords = marker_world_coords\n",
    "        \n",
    "    def estimate_pose(self, image_points):\n",
    "        \"\"\"Returns camera position and rotation matrix\"\"\"\n",
    "        success, rvec, tvec = cv2.solvePnP(\n",
    "            self.marker_world_coords,\n",
    "            np.array(image_points),\n",
    "            self.camera_matrix,\n",
    "            self.dist_coeffs\n",
    "        )\n",
    "        \n",
    "        if not success:\n",
    "            return None, None\n",
    "            \n",
    "        # Convert rotation vector to matrix\n",
    "        R, _ = cv2.Rodrigues(rvec)\n",
    "        \n",
    "        return R, tvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_camera_pose(frame, R, t, points_2d, processed_binary):\n",
    "    # Create visualization window\n",
    "    viz_original = cv2.resize(frame, (640, 480))\n",
    "    viz_processed = cv2.resize(processed_binary, (640, 480))\n",
    "    \n",
    "    # Draw detected points\n",
    "    for point in points_2d:\n",
    "        cv2.circle(viz_original, point, 5, (0, 255, 0), -1)\n",
    "    \n",
    "    # Combine visualizations\n",
    "    viz = np.hstack([viz_original, viz_processed])\n",
    "    \n",
    "    # Add pose information as text\n",
    "    position = -np.matrix(R).T * np.matrix(t)\n",
    "    cv2.putText(viz, f\"Position: {position.flatten()}\", \n",
    "                (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    return viz\n",
    "\n",
    "# Main loop\n",
    "def calibration_tool():\n",
    "    cap = cv2.VideoCapture(0)  # or your video file\n",
    "    detector = IRMarkerDetector()\n",
    "    \n",
    "    # Define your known IR LED positions (example)\n",
    "    marker_positions = np.array([\n",
    "        [0, 0, 0],\n",
    "        [0, 100, 0],\n",
    "        [100, 0, 0],\n",
    "        [100, 100, 0]\n",
    "    ])  # Replace with your actual marker arrangement\n",
    "    \n",
    "    # Camera parameters (you'll need to calibrate these first)\n",
    "    camera_params = {\n",
    "        'fx': 1000,\n",
    "        'fy': 1000,\n",
    "        'cx': 320,\n",
    "        'cy': 240,\n",
    "        'dist_coeffs': [0, 0, 0, 0, 0]\n",
    "    }\n",
    "    \n",
    "    estimator = CameraPoseEstimator(camera_params, marker_positions)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        # Detect IR markers\n",
    "        points_2d, processed = detector.detect(frame)\n",
    "        \n",
    "        if len(points_2d) >= 4:  # Need at least 4 points for reliable pose estimation\n",
    "            R, t = estimator.estimate_pose(points_2d)\n",
    "            if R is not None:\n",
    "                viz = visualize_camera_pose(frame, R, t, points_2d, processed)\n",
    "                cv2.imshow('Calibration Tool', viz)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
